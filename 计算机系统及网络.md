# 计算机网络

## 一、网络体系分层

### 1.1 七层协议
1. 应用层：规定应用程序的数据格式
2. 表示层：
3. 会话层：
4. 传输层：建立"端口到端口"的通信，tcp/udp协议
5. 网络层：ip协议
6. 数据链路层：电信号分组方式。
7. 物理层：传输电信号
### 1.2 四层协议

应用层
运输层
网络层
网络接口层

## 二、互联网协议
参考：
[互联网协议入门(一)](https://www.ruanyifeng.com/blog/2012/05/internet_protocol_suite_part_i.html)

### 2.1 mac地址
> 每块网卡出厂的时候，都有一个全世界独一无二的MAC地址，长度是48个二进制位，通常用12个十六进制数表示。
> MAC地址有局限性，如果两台电脑不在同一个子网络，就无法知道对方的MAC地址，必须通过网关（gateway）转发

### 2.2 数据链路层
以太网规定
>"标头"包含数据包的一些说明项，比如发送者、接受者、数据类型等等；"数据"则是数据包的具体内容。
"标头"的长度，固定为18字节。"数据"的长度，最短为46字节，最长为1500字节。因此，整个"帧"最短为64字节，最长为1518字节。如果数据很长，就必须分割成多个帧进行发送。

### 2.3 广播
> 就算有了MAC地址，系统怎样才能把数据包准确送到接收方？
回答是以太网采用了一种很"原始"的方式，它不是把数据包准确送到接收方，而是向本网络内所有计算机发送，让每台计算机自己判断，是否为接收方。

### 2.4 ip地址
> IP协议的作用主要有两个，一个是为每一台计算机分配IP地址，另一个是确定哪些地址在同一个子网络。
> 知道"子网掩码"，我们就能判断，任意两个IP地址是否处在同一个子网络。方法是将两个IP地址与子网掩码分别进行AND运算（两个数位都为1，运算结果为1，否则为0）
> 回答是不需要，我们可以把IP数据包直接放进以太网数据包的"数据"部分，因此完全不用修改以太网的规格。这就是互联网分层结构的好处：上层的变动完全不涉及下层的结构。

### 2.5 arp协议
> 总之，有了ARP协议之后，我们就可以得到同一个子网络内的主机MAC地址，可以把数据包发送到任意一台主机之上了。

### 2.6 传输层
> "传输层"的功能，就是建立"端口到端口"的通信。相比之下，"网络层"的功能是建立"主机到主机"的通信。只要确定主机和端口，我们就能实现程序之间的交流。

### 2.7 UDP协议
> 必须在数据包中加入端口信息，这就需要新的协议。最简单的实现叫做UDP协议
UDP协议的优点是比较简单，容易实现，但是缺点是可靠性较差，一旦数据包发出，无法知道对方是否收到。

### 2.8 TCP协议
> TCP协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。
> TCP数据包和UDP数据包一样，都是内嵌在IP数据包的"数据"部分。TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。

### 2.9 应用层
> TCP协议可以为各种各样的程序传递数据，比如Email、WWW、FTP等等。那么，必须有不同协议规定电子邮件、网页、FTP数据的格式，这些应用程序协议就构成了"应用层"。


## 三、 socket

**参考：**
[理解socket](https://blog.csdn.net/StromMaybin/article/details/73010280)
[Python 中的 Socket 编程（指南）](https://keelii.com/2018/09/24/socket-programming-in-python/)
[socket的概念和原理](https://www.cnblogs.com/pipci/p/12527394.html)
[Python中Socket的Close方法假关闭Socket连接的问题](https://blog.csdn.net/ztb3214/article/details/17405385)
[tcp 服务端如何判断客户端断开连接](https://blog.csdn.net/tjcwt2011/article/details/78848317)
[端口复用](https://blog.csdn.net/weibo1230123/article/details/79978745)

**我的socket实现代码**
[socket_base.py](code/socket_base.py)
[socket_server_run.py](code/socket_server_run.py)
[socket_client_run.py](code/socket_client_run.py)

**整理socket和网络io方面的东西**

socket是对底层数据传输协议的封装，面临的问题是网络io，解决方法是五种网络io模型
- socket的概念
- socket基本实现
- socket面临的问题-网络io的原因
- 介绍五种网络io模型
- 目前已实现的socket方式
- 整理遇到的问题

socket不同计算机之间进程通信的一种方式，简单来讲，socket实现了服务端和客户端，在客户端发送请求，在服务端监听目标接口的请求，作为一种通信方式，socket可以传递那些信息呢？是基于什么协议呢？

我已经知道计算机通过ip协议可以获取目标计算机的ip地址，完成了定位这个步骤，接下来通过udp和tcp协议，可以实现通信，将数据包以一定格式传输到目标计算机，但是一台计算机上可能同时运行着很多程序，所以会有很多数据包，那么socket本质就是对tcp和udp协议的封装，完成数据-应用的对应，使得数据包和对应的应用关联起来。

为此socket需要在服务端上**指定通信协议是udp/tcp**、**绑定服务端的监听端口**，实际上socket也希望可以支持其他协议；同时，我也知道http是应用层的协议，协议本质是一种规范对吧？那不同的协议是如何被定义和被实现的呢？

> “我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如 果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET等，也 可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。”

- 单线程监听、回复
- 多线程的监听、回复

- timeout会导致报超时错误，而不是中断连接
- server关闭后的端口和地址释放如何手动实现，如何定位异常的server进程？(考虑ip端口复用)
- 堵塞不是判断空数据吗？跟进程挂起有关系吗？；堵塞是等待io，等待时进程挂起

**问题：**
1、如果socket服务端遇到异常退出，但是客户端并没有断开链接，那么地址不能立刻被释放，需要等待一段时间，或者定位到直接kill；可以通过配置端口复用解决

- 在没有client连接的时候，直接断掉server，端口和地址立刻释放
- client和server连接中如果server断掉，那么client不会受影响，依旧可以向server发送消息，但是结果为空
- server断掉ciient的连接之后，client不会立刻断开，这里client要如何断开连接呢？等过一会儿会发现无法send给server，这时会报错；判断返回data是否为空，为空断开
- 使用多线程开启客户端，但服务端现实连接数只有一个，返回结果数少于应该的数量；如果这里的多线程是指同一个连接发送多次请求，那么可能会发生粘包问题
- 按道理，非阻塞io在recv的时候即使没有数据，也会返回数字码，为什么我实验的时候报错了呢？；可能是不同语言的区别，python的非阻塞recv确实会报错
- 了解完sokcet之后，有几个问题，不同的业务类型，例如游戏、线上音频等服务是如何构建相应的socket的呢？在后台开发中，可以从哪些地方进行配置？；了解到本质是文件之后，不同业务的区别就在于，读取时间，刷新时间，文件大小，实时性等，当然这些都是tcp，如果是udp目前还不知道

代码中实现了select_epoll_run和tornado_ioloop_run之后测试发现依旧是阻塞的模式，后台调试之后发现把```time.sleep```改为```asyncio.sleep```之后，就实现了并发，这里我觉得很奇怪，因为我曾经试着把sleep用async封装为一个新函数，但并不行，这里的原因需要再看一下；再次查看发现自己封装的还是有问题的
```
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
```

尝试结果，哪怕都封装为async函数然后丢到loop中，time.sleep依旧是阻塞的，这里引出了一个关键的问题，如果某个逻辑本身是阻塞的，那么必须用async的逻辑重写才可以实现协程，而不是说加上async就可以了，一般来说是不需要我们自己写的，大部分常用的都已经封装好了
```
loop.call_soon
loop.call_later
loop.call_when
```

另外，我并没有添加loop，只是把原本的阻塞函数改为协程函数就可以，那么loop的作用是什么呢？

- async
- await

[WebSocket 与 Socket.IO](https://zhuanlan.zhihu.com/p/23467317)

## 网络io模型
[5种网络IO模型（有图，很清楚](https://zhuanlan.zhihu.com/p/54580385)
[彻底理解 IO 多路复用实现机制](https://juejin.cn/post/6882984260672847879) 
[一文搞懂，网络IO模型](https://zhuanlan.zhihu.com/p/260450151)
[理解阻塞和非阻塞](https://blog.csdn.net/u010236550/article/details/41510995)
[数据包完整性问题](https://blog.csdn.net/rankun1/article/details/50488989)
[聊聊Linux 五种IO模型-理解io多路复用-select/poll](https://www.jianshu.com/p/486b0965c296)
[select和poll简单实用](https://my.oschina.net/SnifferApache/blog/776123)
[python select网络编程详细介绍](https://www.cnblogs.com/lxmhhy/p/6091730.html)
[python epoll使用](https://cloud.tencent.com/developer/article/1568723)
[聊聊IO多路复用之select、poll、epoll详解](https://www.jianshu.com/p/dfd940e7fca2)
[基于tornado的简单socket通信建立](http://www.muzixing.com/pages/2013/11/29/ji-yu-tornadode-jian-dan-sockettong-xin-jian-li.html)[tornado -- ioloop源码解析](http://www.pycircus.com/tornado/2020/06/02/tornado%E7%9A%84ioloop%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/)
[异步网络模型](https://tech.youzan.com/yi-bu-wang-luo-mo-xing/)


> Socket起源于UNIX，在Unix一切皆文件的思想下，进程间通信就被冠名为文件描述符（file desciptor）
> 句柄值：本质就是文件，跟文件描述符经常被混用，建议使用文件描述符

1、同步阻塞io
当程序向内核请求数据，但内核还未准备好的时候，程序等待导致阻塞
2、同步非阻塞io
当程序向内核请求数据，但内核还未准备好的时候，程序不等待返回结果
3、io多路复用
4、信号驱动io
用于udp协议
5、异步io

select/poll

> select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。
> select或poll调用之后，会阻塞进程，与blocking IO阻塞不同在于，此时的select不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理。如何知道有一部分数据到达了呢？监视的事情交给了内核，内核负责数据到达的处理。也可以理解为"非阻塞"吧。

- 在select的时候，是不能新建连接的？

- epoll
epoll_create() 、epoll_wait 
> LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
> 
ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。

看了诸多文章后，我的理解是对于socket服务来讲，异步和非异步的区别在于一个读取数据操作发起后是否一直等待，如果一直等待不能新建其他tcp连接，那就是同步，否则就是异步。明显这里的异步概念是可以用多线程实现的，有人说对于多线程中每个单线程还是同步阻塞的，对，没错，但是不要搞错了，之所以把多线程优化为io多路复用是因为多线程的资源问题，到了io多路复用提升的是性能，但没有改变本质，所以这个变化属于异步实现中的优化。好好想想，当我们讨论同步和异步的时候到底在讨论是什么，是对于服务来说，还是对于程序来说的，以及为什么我们要异步。

思考两个场景：
场景一：十个任务
假如我有十个任务，对于任务实现来说，同步就是一个接着一个的实现，异步就是十个同时开始，不论并行还是并发，这里仔细想想，并行省掉的是什么？是前个任务对后个任务对阻塞时间，不必再等待前者完成才能继续了，并且每个任务都有自己独立的计算单元，同时进行cpu计算任务；而并发呢？省掉的是io等待时间，让cpu的时间片分布到每个任务上，这里为什么可以提升效率？因为每个任务包括**计算时间**和**io时间**，而这两个部分是由cpu和其他系统资源分别处理的，也就是说计算和io可以同时进行，因为有各自的处理单元，这里我们节省的时间是什么，是io的等待时间，当io出现的时候，cpu会转到下个任务的计算部分，而并非等待io结束。所以前者适合计算较多的任务，后者适合io较多的任务。
场景二：一个任务
假如我有一个任务，对于用户来说，同步就是我一直等任务完成得到结果，异步就是我拿到一个临时结果，然后等真实结果完成后再主动联系用户。这里为什么不等待任务完成给用户结果呢？这里是因为当有很多个这样的任务的时候，对于服务器来说，压力就比较大了，同时挂起多个阻塞任务是对服务器资源的浪费。而这里我们用的是什么呢？生产消费模型，产生任务的环节叫做生产，将任务作为产品放到队列，完成任务的环节叫做消费。从而将任务发起和任务实现分离，减轻服务器压力，提高任务容错率，以及更好的用户体验。但这里就不再是线程和协程的异步，而是进程，一般想celery都是拥有独立进程的，作为一个程序单独运行，可以将把任务丢给celery，并且把消费行为绑定给任务，例如说函数实现、接口调用等等的，这样就可以做到了效果最好的异步了。

思考：await是如何通知主程序io完成的？

- Reactor
> 核心思想：将关注的I/O事件注册到多路复用器上，一旦有I/O事件触发，将事件分发到事件处理器中，执行就绪I/O事件对应的处理函数中。模型中有三个重要的组件：
> 
多路复用器：由操作系统提供接口，Linux提供的I/O复用接口有select、poll、epoll；
事件分离器：将多路复用器返回的就绪事件分发到事件处理器中；
事件处理器：处理就绪事件处理函数。
> 流程：
注册I/O就绪事件处理器；
事件分离器等待I/O就绪事件；
I/O事件触发，激活事件分离器，分离器调度对应的事件处理器；
事件处理器完成I/O操作，处理数据.

- Proactor
>发起I/O异步操作，注册I/O完成事件处理器;
事件分离器等待I/O操作完成事件；
内核并行执行实际的I/O操作，并将结果数据存入用户自定义缓 冲区；
内核完成I/O操作，通知事件分离器，事件分离器调度对应的事件处理器；
事件处理器处理用户自定义缓冲区中的数据。

这些属于我个人的理解，我看五种io模型最后面一种是异步io，果然是将处理函数也绑定到了事件上



## 四、tcp建立连接和断开
参考：
[TCP的三次握手与四次挥手理解及面试题](https://blog.csdn.net/qq_38950316/article/details/81087809)
[TCP报文格式](https://www.cnblogs.com/aspirant/p/7224696.html)


### 三次握手

- 客户端-服务端：发送syn（同步序列编号）包，序列号为j，进入syn_sent状态
- 服务端-客户端：发送syn包（k）和ack包（j+1），进入syn_recv状态
- 客户端-服务端：发送ack包（k+1），双方进入连接建立的状态

### 四次挥手

- 主动关闭方-被动关闭方：发送一个fin包，我就要关闭连接了
- 被动关闭方-主动关闭方：发送一个ack包，表明已经收到了
- 被动关闭方-主动关闭方：发送-个fin包，我也要关闭了
- 主动关闭方-被动关闭方：发送一个ack包，好的，都进入关闭的状态

报文结构：(flag='ACK', ACK=1)，(flag='SYN', SYN=1)

假使双方同时关闭呢？假使服务端提出关闭也是一样的吗？

## 五、http和https
是建立在tcp上的应用，区别在于http使用明文传输数据，而https使用ssl进行身份验证和数据加密，所以更加安全

请求：
一个HTTP请求到服务器的请求消息由请求行（request line）、请求头部（header）、空行和请求数据四个部分组成
响应：
HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文

## 常见问题
[经典面试题：从URL 输入到页面展现到底发生什么](https://blog.fundebug.com/2019/02/28/what-happens-from-url-to-webpage/)
[终于有人把正向代理和反向代理解释的明明白白了](https://cloud.tencent.com/developer/article/1418457)

# 计算机系统

## 进程、线程和协程
[如何回答面试官提出的关于进程、线程和协程的问题](https://blog.csdn.net/wanghao72214/article/details/109555398)
[协程究竟比线程能省多少开销？](https://zhuanlan.zhihu.com/p/80037638)
[为什么协程切换的代价比线程切换低? - 暗淡了乌云的回答 - 知乎](https://www.zhihu.com/question/308641794/answer/572499202)

进程是操作系统分配资源的最小单元, 线程是操作系统调度的最小单元，协程是用户级的线程

> 进程：代码段用来存放处理器执行的代码；数据段存放全局和静态变量；堆用来存放动态分配的内存；栈用来存放局部变量、函数参数和寄存器的值等。
> 线程：它与同属一个进程的其他的线程共享进程拥有的资源，线程独自拥有少量的程序计数器、数据寄存器和栈等运行中必不可少的私有资源。
> 协程有自己的上下文，同属一个进程的协程共享进程拥有的系统资源。协程的切换由自己控制，由切换到其他协程由当前协程来控制。与线程和进程相比，协程的最大优势在于其“轻量级”，可以轻松创建上百万个而不会导致系统资源衰竭。

- 为什么协程可以创建的数量远大于线程和进程？
创建协程所需要的内存资源远远小于进程和线程
> 在空间上，协程初始化创建的时候为其分配的栈有2KB。而线程栈要比这个数字大的多，可以通过ulimit 命令查看，一般都在几兆

- 为什么协程切换速度比线程和进程都要快？
> 我们用实验的方式验证了Linux进程和线程的上下文切换开销，大约是3-5us之间
> 平均每次协程切换的开销是（655035993-415197171)/2000000=120ns。相对于前面文章测得的进程切换开销大约3.5us，大约是其的三十分之一。比系统调用的造成的开销还要低。
> 所谓进程切换就是从运行中的进程中收回处理器，然后再使待运行进程来占用处理器。从某个进程收回处理器，实质上就是把进程运行过程中寄存器的中间数据存放到进程的堆栈。让某个进程来占用处理器，实质上是把这个进程存放在堆栈中的寄存器数据恢复到处理器的寄存器中去，并把待运行进程的断点送入处理器的程序计数器。
> 一个进程存储在处理器各寄存器中的中间数据叫做进程的上下文，所以进程切换就是被中止进程与待运行进程上下文的切换。进程切换上下文时，需要进出操作系统内核，并进行寄存器数据切换等工作，都需要一定的时间开销。
> 线程切换除了上下文的切换外，还有内核调度的消耗，例如一些用户态状态切换等等，但协程只需要切换上下文即可，可能是因为这里使得协程的切换效率更高

写线程和协程的时候也有感觉，线程是由系统调度的，用户只是给线程分配了任务，但是协程是自己调度的，用户需要设置协程切换的位置。

## 通信
[进程间通信之管道（pipe、fifo）](https://www.cnblogs.com/MrListening/p/5858358.html)
进程之间进行通信常用的有几种方式：管道，消息队列， 信号量， 共享内存；线程同步通常有4中方式： 临界区、事件、互斥量、信号量。
线程通信

### 管道：
匿名管道：双工的通信方式，只允许亲缘进程通信
有名管道：双工的通信方式，允许非亲缘进程通信
特点：
1. 只能单向通信
2. 只能血缘关系的进程进行通信
3. 依赖于文件系统
4、生命周期随进程

### 信号量
信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

### 消息队列
消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

### 信号
信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

### 共享内存
共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

### 套接字
套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。


## 进程
[进程间8种通信方式详解](https://cloud.tencent.com/developer/article/1690556)
进程有5种状态：
新建态：刚刚创建的进程，操作系统还没有把它加入到可执行进程组中，通常是进程控制块已经创建但是还没有加载到内存中的进程。
就绪态：进程已经做好了准备，只要有机会就开始执行。
运行态：该进程正在执行。
阻塞态（等待态）：进程在某些事情发生前不能执行，等待阻塞进程的事件完成。
退出态：操作系统从可执行进程组中释放出的进程，由于自身或某种原因停止运行。

## 线程
### 多线程同步
[Python信号量](https://haicoder.net/python/python-thread-semaphore.html)
[进程间通信的方式（四）：信号量](https://zhuanlan.zhihu.com/p/37894026)
信号量到底是用来限制资源访问，还是用来同步不同的线程信息的？
> 同步：处理竞争就是同步，安排进程执行的先后顺序就是同步，每个进程都有一定的个先后执行顺序。
互斥：互斥访问不可共享的临界资源，同时会引发两个新的控制问题（互斥可以说是特殊的同步）。
竞争：当并发进程竞争使用同一个资源的时候，我们就称为竞争进程。
> 共享资源通常分为两类：一类是互斥共享资源，即任一时刻只允许一个进程访问该资源；另一类是同步共享资源，即同一时刻允许多个进程访问该资源；信号量是解决互斥共享资源的同步问题而引入的机制。

原来是我没有理解到同步的意思

> 信号量是由操作系统管理的一种抽象数据类型，用于在多线程中同步对共享资源的使用。本质上说，信号量是一个内部数据，用于标明当前的共享资源可以有多少并发读取。
也可以简单的理解为，信号量是多把锁，同时允许多个线程来更改数据，而互斥锁同时只允许一个线程更改数据。Python信号量使用语法：
```
import threading
sem = threading.Semaphore(3)
sem.acquire()
sem.release()
```

## 内存
缓存区溢出指计算机在向缓存区填充数据时超过了缓存区的最大值， 溢出的数据覆盖在了合法数据上。
其危害： 程序崩溃， 导致拒绝服务。跳转并执行恶意代码。
造成缓存区溢出的原因主要是没有对用户的输入进行检查。



# linux
## 一些常用操作（面试）
查看端口号是否被占用
netstat -anp|grep 80

如何为一个目录下的所有文件添加权限
r：4，w：2，x：1
chmod -R 777 apache-tomcat-8.5.20/

如果要删除一个文件，那么需要拥有这个文件所在目录的write权限

## 监控命令
```
# 查看丢包和延时
mtr google.com
# iperf测试带宽，iperf是c/s模型应用，所以必须先运行iperf server
# 在一台主机上（服务端）：
iperf -u -s
# 另一台主机上（客户端）：
iperf -u -c 10.0.0.1(服务端的ip地址)
# 第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如果不设置第二个参数，那么可以一直运行
# 可以查看cpu、内存、io
vmstat 2 1
```


# 一、数据库概念整理
## 1. 数据库分类与设计
[非关系型数据库（NOSQL）和关系型数据库（SQL）区别详解](https://www.debugger.wiki/article/html/1612109880275721)
关系型数据库：sql、sqlite、PostgreSQL、mysql、oracle
非关系型数据库：Redis、Memcached、MongoDB

mysql是由server层和存储引擎

postgresql和mysql的比较

mysql中的数据表类型：INNODB和BDB类 

mongodb用于存储对象，例如json类数据

## 2. 常用概念
[数据库——彻底明白超键、候选键、主键、外键](https://blog.csdn.net/jerry11112/article/details/78160771)

### 2.1 超键、候选键、主键、外键
> 超键(super key): 在关系中能唯一标识元组的属性集称为关系模式的超键
候选键(candidate key): 不含有多余属性的超键称为候选键。也就是在候选键中，若再删除属性，就不是键了！
主键(primary key): 用户选作元组标识的一个候选键程序主键
外键(foreign key)：如果关系模式R中属性K是其它模式的主键，那么k在模式R中称为外键。

### 2.2 索引
[Mysql索引面试题](https://www.cnblogs.com/williamjie/p/11187470.html)
[PostgreSQL 9种索引的原理和应用场景](https://developer.aliyun.com/article/111793)
- 单列索引
- 组合索引
- 唯一索引
- 局部索引：针对符合特定条件数据的索引
- 隐式索引：数据库自动创建的索引

索引的本质是针对非主键的、常用的、具有散列性质的字段建立的快捷查询，优点是可以快速读取到目标数据，缺点是每次修改删除都要对索引同样操作，使得修改和删除的效率变低，因为索引的设置要高效精准，不要在无用字段上建立过多索引。

MySQL主要有两种结构：Hash索引和B+Tree索引，PostgreSQL居然有9种索引，以后看一下，一般默认的都是B+Tree索引

排序查询用B+Tree索引，单行精确查询用hash索引，如果hash索引要排序，不可避免要全表扫描

### 2.3 视图和存储过程
[视图和存储过程的区别](https://www.cnblogs.com/shengchanlix/archive/2011/05/30/2063156.html)
- 视图是一个虚拟表，适合于从单个表格中提取几个目标数据，缺点是不适合多表查询的情况
- 存储过程是预设在数据库中的经过编译的sql语句，执行效率高，适用于高频执行的请求，缺点移植性差，过多存储过程会并且如果有耦合的话会占用数据库资源

视图的存储过程的区别在于视图依旧是表的形式，而存储过程着重函数形式，可以接受参数，两者本质都是经过编译的预设的sql语句

### 2.4 触发器
触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器定义在数据表上，需要确定触发条件、触发时间（是指触发条件前后）、触发内容。

一般不要使用触发器，尤其是插入修改频繁的表，消耗资源较多，目前来看触发器所能做的事情仍然比较局限，可以使得应用在数据库端确保数据的完整性以及日志记录，数据校验等操作。

触发器可以跟存储过程耦合

### 2.5 事务和锁
[数据库的事务隔离与锁机制有什么差别和联系](https://www.zhihu.com/question/23242151/answer/59821385)
[深入理解数据库事务](https://zhuanlan.zhihu.com/p/43493165)
[MySQL探秘(四)MySQL事务与锁详解](https://princeli.com/mysql%E6%8E%A2%E7%A7%98%E5%9B%9Bmysql%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81%E8%AF%A6%E8%A7%A3/)

#### 2.5.1 事务
事务(Transaction)是单个的工作单元，具有ACID，原子性、一致性、隔离性和持久性

- 原子性：事务必须是原子工作单元，对于其数据修改，要么全都执行，要么全都不执行。
- 一致性：事务在完成时，必须使所有的数据都保持一致状态。在相关数据库中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事物结束时，所有的内容数据结果都必须是正确的。
- 隔离性：由并发事务所作的修改必须与任何其他并发事务所作的修改隔离，保证事务查看数据时数据处于的状态，只能是另一并发事务修改它之前的状态或者是另一事务修改它之后的状态，而不能中间状态的数据。
- 持久性：事务完成之后对系统的影响是永久性的。

**没有哪个数据库都以完美做到这四点，不同数据库在这四个维度上有不同的优劣**

#### 2.5.2 事务回滚

**一般情况下，一句sql就是一个事务，如果想在一个事务中包括多个语句，就需要开启和结束事务。**
但是...，事务报错后不会自动回滚，需要手动回滚，所以我们需要知道在事务中已经执行的sql是否执行成功
- for update：加上行锁，但是这个感觉不太靠谱
- 通过某种方式获取

#### 2.5.3 事务隔离
事务隔离的四个级别，mysql默认是可重复读
- read uncommitted（读未提交）
- read committed（读已提交）
- repeatable read（可重复读）
- serializable（串行化）

事务隔离要解决的问题
|隔离等级|产生的问题|可以解决的问题|
|:--:|:--:|:--:|
|读未提交|脏读/脏写||
|读已提交|不可重复读|脏读/脏写|
|可重复读|幻读|不可重复读|
|串行化||幻读|

- 脏读：数据在修改过程中被读取了，但回滚使得读取的是错误数据
- 脏写：数据在修改过程中被另一个事务修改了，但回滚使得另一个事务修改无效
- 不可重复读：两次读取中间数据已经被修改，所以不一致
- 幻读：两次读取间新增或删除数据，所以数据量发生变化


不同隔离级别用到了不同的锁

- 乐观锁：假定访问资源的并发进程不会冲突，如果冲突则重试
- 悲观锁：假定访问资源都会冲突，每次都要上锁，并发进程需要等待解锁才能执行
- 排他锁：也就是写锁，即在进行写操作时，不允许其他进程进行写操作
- 共享锁：也就是读锁，多个进程可以同时读取数据，并保证数据不被修改

**我上面参考的知乎的回答说，读已提交使用了写锁，可重复读使用了读锁，而读锁被持有的时候不可修改，可是第二篇文章说，读的时候实际上可以被修改，只是对读这个事务不可见，这就有意思了，哪种说法是对的呢？有时间可以看下第三篇文章详细了解一下**

mysql使用mvcc，读的是快照


#### 2.5.4 锁

从数据库的角度

>行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。
特点
开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

> 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。
特点
开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

> 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁
特点
开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

死锁
形成的四个条件
> 互斥条件：一个资源每次只能被一个线程使用。
请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
不剥夺条件：线程已获得的资源，在未使用完之前，不能强行剥夺。
循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。

解决死锁：破坏四个形成条件任意一个

### 2.6 三个范式
> 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。
第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。
第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在"A → B → C"的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y

我的理解是
- 第一范式：每列对应的属性不可再分，是单一属性
- 第二范式：每行有一个唯一id可以区分
- 第三范式：所有非关键属性依赖主键，不存在非关键对其他候选键的依赖

# 二、数据库操作
[我之前的sql笔记](https://app.gitbook.com/@paisins-2/s/sql/sql)

## 1、基础
```
# 安装好PostgreSQL之后，初始化资料库，因为我之前有过一个版本的，所以重命名了一下
initdb /usr/local/var/postgres_13
# 启动
pg_ctl -D /usr/local/var/postgres_13 -l /usr/local/var/postgres_13/server.log start
# 创建使用者账户
createuser username -P
我的密码：英文名字
# 创建连接数据库
createdb testdb
psql testdb
psql -h localhost -p 5432 -U username testdb
# 查询所有数据库
\l（这是L）
# 基础操作过多就不在这里一一写了
```

模式Schema：用于切分不同业务逻辑，便于管理数据表
like匹配符：%代表多个符号，下划线代表单个符号
WITH子句：有助于将复杂的大型查询分解为更简单的表单，这个用法很有意思，有点shell中管道的意思
having：相当于group by 的where，加判断条件
union：会去重，保留重复项，请使用union all，这个功能严格来讲可以在后台的部分实现，出现合并后还有操作

## 核心用法
join
- CROSS JOIN ：交叉连接，第一个表的每一行都跟第二个表交叉，很产生大量的数据，慎用
- INNER JOIN...ON...：内连接，将第一个表的每一行跟第二个表的每一行比较on之后的条件，符合则保留
- LEFT OUTER JOIN：左外连接，以左边为准，左边全部保留，右边没有为空
- RIGHT OUTER JOIN：右外连接，以右边为准，右边全部保留，左边没有为空
- FULL OUTER JOIN：全外连接，先保留左边，再保留右边

后面三个属于外连接，本质是先执行内连接，然后再内连接上进行扩展

## 善用数据库内部函数 


# 三、数据库软件
> 目前这部分是根据面试题整理的，待想要一个知识框架后再进行细分整理

## 1、redis
### Redis支持的数据类型
字符串，集合， 有序集合，哈希， 列表
> redis的hash表使用链接地址法解决冲突的

### redis持久化的几种方式
[Redis详解（七）------ AOF 持久化](https://juejin.cn/post/6844904175474589710)
1. RDB快照： 默认使用这种方式，将数据快照存放在特定的二进制文件中。
2. AOF: 将每一条命令都储存， 恢复时再将每一天命令进行运行。
> RDB持久化方案是按照指定时间间隔对你的数据集生成的时间点快照（point-to-time snapshot）。它以紧缩的二进制文件保存Redis数据库某一时刻所有数据对象的内存快照，可用于Redis的数据备份、转移与恢复。到目前为止，仍是官方的默认支持方案。
> AOF是Append Only File的缩写，它是Redis的完全持久化策略，从1.1版本开始支持；这里的file存储的是引起Redis数据修改的命令集合（比如：set/hset/del等），这些集合按照Redis Server的处理顺序追加到文件中。当重启Redis时，Redis就可以从头读取AOF中的指令并重放，进而恢复关闭前的数据状态。

RDB默认开启，AOF默认关闭，需要修改配置文件启动；4.0版本支持混合持久化

Redis使用AOF方式持久化，aof文件不断增大，会触发自动重写，当然也可以手动重写
> 也就是说 AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。

> AOF 文件重写触发机制：通过 redis.conf 配置文件中的 auto-aof-rewrite-percentage：默认值为100，以及auto-aof-rewrite-min-size：64mb 配置，也就是说默认Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。
>   这里再提一下，我们知道 Redis 是单线程工作，如果 重写 AOF 需要比较长的时间，那么在重写 AOF 期间，Redis将长时间无法处理其他的命令，这显然是不能忍受的。Redis为了克服这个问题，解决办法是将 AOF 重写程序放到子程序中进行，这样有两个好处：
>   ①、子进程进行 AOF 重写期间，服务器进程（父进程）可以继续处理其他命令。
>   ②、子进程带有父进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。
>   使用子进程解决了上面的问题，但是新问题也产生了：因为子进程在进行 AOF 重写期间，服务器进程依然在处理其它命令，这新的命令有可能也对数据库进行了修改操作，使得当前数据库状态和重写后的 AOF 文件状态不一致。
>   为了解决这个数据状态不一致的问题，Redis 服务器设置了一个 AOF 重写缓冲区，这个缓冲区是在创建子进程后开始使用，当Redis服务器执行一个写命令之后，就会将这个写命令也发送到 AOF 重写缓冲区。当子进程完成 AOF 重写之后，就会给父进程发送一个信号，父进程接收此信号后，就会调用函数将 AOF 重写缓冲区的内容都写到新的 AOF 文件中。
>   这样将 AOF 重写对服务器造成的影响降到了最低。

### redis的事务
使用关键字multi开启事务， 使用exec执行事务中的语句，它可以执行多条语句， 所有的命令按照先进先运行的的运行， 不会被其他的命令加塞。

### 并发
redis是单线程的，线程安全，但是有并发问题，redis有事务，但是没有原子性，避免并发冲突可以用
```
watch
get和set改为incr或者incrby
```

### 内存淘汰机制
redis 提供了6种数据淘汰策略：

>volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据进行淘汰
volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据进行淘汰
volatile-random：从已设置过期时间的数据集（server.db[i].expires）中选择任意数据进行淘汰
allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（最常用）
allkeys-random：从数据集（server.db[i].dict）中选择任意数据进行淘汰
no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错

>4.0版本后，又新增加了以下两种：
volatile-lfu：从已设置过期时间的数据集 (server.db[i].expires) 中挑选最不经常使用的数据进行淘汰
allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

### redis集群
#### 哈希槽
[redis cluster集群——高可用 （哈希槽）](https://blog.csdn.net/Rapig1/article/details/102488359)
[吃透了这些Redis知识点，面试官一定觉得你很NB](https://zhuanlan.zhihu.com/p/68694458)


### 修改配置文件
1、修改密码
config set requirepass test123
2、数据库个数
Redis的数据库个数默认是16个（0-15），修改方式是修改redis.conf配置文件databases参数后的数量，重启redis后生效

## 2、mysql

### 慢查询
[MySQL数据库慢查询问题排查方法](https://zhuanlan.zhihu.com/p/66275448)
慢查询的数量保存在mysql库里面的slow_log表。
```
SELECT * FROM slow_log where start_time > '2019/05/19 00:00:00'; 
```
原因可能有很多
- 大量查询堵塞

### 查询优化
[万字总结：学习MySQL优化原理，这一篇就够了！](https://dbaplus.cn/news-155-1531-1.html)
- 加索引
- 尽量不用全表遍历的语句

## 3、mongodb
查询功能比较强大，擅长查询 JSON 数据，能存储海量数据，但是不支持事务。

# 数据库存储与内存，qps与cpu关系

# 数据库数据备份和迁移

# 安全
- 如何避免sql注入？
如果知道目标数据的类型，通过判断整型或者判断是否存在特殊符号，就可以避免，但是假如输入的参数本身就是文本，那就有可能有问题了，但是有个简单的方法，将空格等特殊字符替换为某些特殊字符，或者文本直接以二进制的形式存储，使用的时候再逆处理一遍即可。

## 面试问题
1、数据库的数据是实时更新的吗？每点击一次，数据库数据修改一次？
这个我没有找到答案，我认为是实时更新的，如果数据库没有设置主从结构的话，每点击一次数据也就修改一次。
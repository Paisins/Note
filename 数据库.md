# 一、数据库概念整理

数据库的目标是高效存取数据，要面对以下问题
1、同步问题
- 缓存和数据库：先锁数据库，然后修改缓存，然后修改数据库
- 主从数据库：binlog

2、并发问题
- 如何实现高并发
- 如何应对冲突问题：锁

3、误删问题

- 误删单行：按照快照回滚，然后修改操作日志，重新执行
- 误删表（不同误删方法）：

4、中断/崩溃问题
- 事务回滚

5、高效查询
- 索引/检查索引是否生效

## 1. 数据库
postgresql和mysql的比较
mongodb用于存储对象，例如json类数据

## 2. 常用概念
### 数据库分类
[非关系型数据库（NOSQL）和关系型数据库（SQL）区别详解](https://www.debugger.wiki/article/html/1612109880275721)
关系型数据库：sql、sqlite、PostgreSQL、mysql、oracle
非关系型数据库：Redis、Memcached、MongoDB

### 2.1 超键、候选键、主键、外键
[数据库——彻底明白超键、候选键、主键、外键](https://blog.csdn.net/jerry11112/article/details/78160771)

> 超键(super key): 在关系中能唯一标识元组的属性集称为关系模式的超键
候选键(candidate key): 不含有多余属性的超键称为候选键。也就是在候选键中，若再删除属性，就不是键了！
主键(primary key): 用户选作元组标识的一个候选键程序主键
外键(foreign key)：如果关系模式R中属性K是其它模式的主键，那么k在模式R中称为外键。

### 2.2 索引
[Mysql索引面试题](https://www.cnblogs.com/williamjie/p/11187470.html)
[PostgreSQL 9种索引的原理和应用场景](https://developer.aliyun.com/article/111793)

#### 索引基本概念
- 单列索引
- 组合索引
- 唯一索引
- 主键索引
- 非主键索引：
- 局部索引：针对符合特定条件数据的索引
- 隐式索引：数据库自动创建的索引
- 聚簇索引：b+树上存整行数据就叫聚簇索引
- 非聚簇索引：b+树上存非主键的值叫非聚簇索引

**概念**
索引的本质是针对非主键的、常用的、具有散列性质的字段建立的快捷查询，优点是可以快速读取到目标数据，缺点是每次修改删除都要对索引同样操作，使得修改和删除的效率变低，因为索引的设置要高效精准，不要在无用字段上建立过多索引。

**类型**
MySQL主要有两种结构：Hash索引和B+Tree索引，PostgreSQL居然有9种索引，以后看一下，一般默认的都是B+Tree索引

**区别**
排序查询用B+Tree索引，单行精确查询用hash索引，如果hash索引要排序，不可避免要全表扫描
B+树允许出现重复值
哈希索引不支持多列联合索引的最左匹配规则 

#### 组合索引
将多列字段作为索引，根据最左匹配原则，也就是当查询条件最左边的是组合索引的第一个字段的时候会使用组合索引
如果查询内容刚好是组合索引的其他字段，那么则不会回表查询一次，这种查询一次的叫做**覆盖索引**

#### 主键索引和非主键索引
主键索引的查询要效率更高，原因是直接根据主键定位到该行，读取数据，属于一次查询；而非主键索引需要根据条件找到主键，再根据主键查询其他字段，需要回表查询多次

### 2.3 视图和存储过程
[视图和存储过程的区别](https://www.cnblogs.com/shengchanlix/archive/2011/05/30/2063156.html)
- 视图是一个虚拟表，适合于从单个表格中提取几个目标数据，缺点是不适合多表查询的情况
- 存储过程是预设在数据库中的经过编译的sql语句，执行效率高，适用于高频执行的请求，缺点移植性差，过多存储过程会并且如果有耦合的话会占用数据库资源

视图的存储过程的区别在于视图依旧是表的形式，而存储过程着重函数形式，可以接受参数，两者本质都是经过编译的预设的sql语句

### 2.4 触发器
触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器定义在数据表上，需要确定触发条件、触发时间（是指触发条件前后）、触发内容。

一般不要使用触发器，尤其是插入修改频繁的表，消耗资源较多，目前来看触发器所能做的事情仍然比较局限，可以使得应用在数据库端确保数据的完整性以及日志记录，数据校验等操作。

触发器可以跟存储过程耦合

### 2.5 事务和锁
[数据库的事务隔离与锁机制有什么差别和联系](https://www.zhihu.com/question/23242151/answer/59821385)
[深入理解数据库事务](https://zhuanlan.zhihu.com/p/43493165)
[MySQL探秘(四)MySQL事务与锁详解](https://princeli.com/mysql%E6%8E%A2%E7%A7%98%E5%9B%9Bmysql%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81%E8%AF%A6%E8%A7%A3/)

#### 2.5.1 事务
事务(Transaction)是单个的工作单元，具有ACID，原子性、一致性、隔离性和持久性

- 原子性：事务必须是原子工作单元，对于其数据修改，要么全都执行，要么全都不执行。
- 一致性：事务在完成时，必须使所有的数据都保持一致状态。在相关数据库中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事物结束时，所有的内容数据结果都必须是正确的。
- 隔离性：由并发事务所作的修改必须与任何其他并发事务所作的修改隔离，保证事务查看数据时数据处于的状态，只能是另一并发事务修改它之前的状态或者是另一事务修改它之后的状态，而不能中间状态的数据。
- 持久性：事务完成之后对系统的影响是永久性的。

**没有哪个数据库都以完美做到这四点，不同数据库在这四个维度上有不同的优劣**

#### 2.5.2 事务回滚

**一般情况下，一句sql就是一个事务，如果想在一个事务中包括多个语句，就需要开启和结束事务。**
但是...，事务报错后不会自动回滚，需要手动回滚，所以我们需要知道在事务中已经执行的sql是否执行成功
- for update：加上行锁，但是这个感觉不太靠谱
- 通过某种方式获取

#### 2.5.3 事务隔离
事务隔离的四个级别，mysql默认是可重复读
- read uncommitted（读未提交）
- read committed（读已提交）
- repeatable read（可重复读）
- serializable（串行化）

事务隔离要解决的问题
|隔离等级|产生的问题|可以解决的问题|
|:--:|:--:|:--:|
|读未提交|脏读/脏写||
|读已提交|不可重复读|脏读/脏写|
|可重复读|幻读|不可重复读|
|串行化||幻读|

- 脏读：数据在修改过程中被读取了，但回滚使得读取的是错误数据
- 脏写：数据在修改过程中被另一个事务修改了，但回滚使得另一个事务修改无效
- 不可重复读：两次读取中间数据已经被修改，所以不一致
- 幻读：两次读取间新增或删除数据，所以数据量发生变化


不同隔离级别用到了不同的锁

- 乐观锁：假定访问资源的并发进程不会冲突，如果冲突则重试
- 悲观锁：假定访问资源都会冲突，每次都要上锁，并发进程需要等待解锁才能执行
- 排他锁：也就是写锁，即在进行写操作时，不允许其他进程进行写操作
- 共享锁：也就是读锁，多个进程可以同时读取数据，并保证数据不被修改

**我上面参考的知乎的回答说，读已提交使用了写锁，可重复读使用了读锁，而读锁被持有的时候不可修改，可是第二篇文章说，读的时候实际上可以被修改，只是对读这个事务不可见，这就有意思了，哪种说法是对的呢？有时间可以看下第三篇文章详细了解一下**

mysql使用mvcc，读的是快照


#### 2.5.4 锁
从数据库的角度

>行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。
特点
开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

> 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。
特点
开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

> 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁
特点
开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

死锁
形成的四个条件
> 互斥条件：一个资源每次只能被一个线程使用。
请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
不剥夺条件：线程已获得的资源，在未使用完之前，不能强行剥夺。
循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。

解决死锁：破坏四个形成条件任意一个

### 2.6 三个范式
> 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。
第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。
第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在"A → B → C"的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y

我的理解是
- 第一范式：每列对应的属性不可再分，是单一属性
- 第二范式：每行有一个唯一id可以区分
- 第三范式：所有非关键属性依赖主键，不存在非关键对其他候选键的依赖

### 2.7 日志


### 2.8 sql语句分类
SQL 语句主要可以划分为以下 3 个类别：
DDL（Data Definition Languages）语句：数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象的定义。常用的语句关键字主要包括 create、drop、alter等。
DML（Data Manipulation Language）语句：数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性，常用的语句关键字主要包括 insert、delete、udpate 和select 等。(增添改查）
DCL（Data Control Language）语句：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括 grant、revoke 等。

# 二、数据库操作
[我之前的sql笔记](https://app.gitbook.com/@paisins-2/s/sql/sql)

## 1、基础
```
# 安装好PostgreSQL之后，初始化资料库，因为我之前有过一个版本的，所以重命名了一下
initdb /usr/local/var/postgres_13
# 启动
pg_ctl -D /usr/local/var/postgres_13 -l /usr/local/var/postgres_13/server.log start
# 创建使用者账户
createuser username -P
我的密码：英文名字
# 创建连接数据库
createdb testdb
psql testdb
psql -h localhost -p 5432 -U username testdb
# 查询所有数据库
\l（这是L）
# 基础操作过多就不在这里一一写了
```

模式Schema：用于切分不同业务逻辑，便于管理数据表
like匹配符：%代表多个符号，下划线代表单个符号
WITH子句：有助于将复杂的大型查询分解为更简单的表单，这个用法很有意思，有点shell中管道的意思
having：相当于group by 的where，加判断条件
union：会去重，保留重复项，请使用union all，这个功能严格来讲可以在后台的部分实现，出现合并后还有操作

## 核心用法
join
- CROSS JOIN ：交叉连接，第一个表的每一行都跟第二个表交叉，很产生大量的数据，慎用
- INNER JOIN...ON...：内连接，将第一个表的每一行跟第二个表的每一行比较on之后的条件，符合则保留
- LEFT OUTER JOIN：左外连接，以左边为准，左边全部保留，右边没有为空
- RIGHT OUTER JOIN：右外连接，以右边为准，右边全部保留，左边没有为空
- FULL OUTER JOIN：全外连接，先保留左边，再保留右边

后面三个属于外连接，本质是先执行内连接，然后再内连接上进行扩展

## 善用数据库内部函数 


# 三、数据库软件
> 目前这部分是根据面试题整理的，待想要一个知识框架后再进行细分整理

## 1、redis
### Redis支持的数据类型
字符串，集合， 有序集合，哈希， 列表
> redis的hash表使用链接地址法解决冲突的

### redis持久化的几种方式
[Redis详解（七）------ AOF 持久化](https://juejin.cn/post/6844904175474589710)
1. RDB快照： 默认使用这种方式，将数据快照存放在特定的二进制文件中。
2. AOF: 将每一条命令都储存， 恢复时再将每一天命令进行运行。
> RDB持久化方案是按照指定时间间隔对你的数据集生成的时间点快照（point-to-time snapshot）。它以紧缩的二进制文件保存Redis数据库某一时刻所有数据对象的内存快照，可用于Redis的数据备份、转移与恢复。到目前为止，仍是官方的默认支持方案。
> AOF是Append Only File的缩写，它是Redis的完全持久化策略，从1.1版本开始支持；这里的file存储的是引起Redis数据修改的命令集合（比如：set/hset/del等），这些集合按照Redis Server的处理顺序追加到文件中。当重启Redis时，Redis就可以从头读取AOF中的指令并重放，进而恢复关闭前的数据状态。

RDB默认开启，AOF默认关闭，需要修改配置文件启动；4.0版本支持混合持久化

Redis使用AOF方式持久化，aof文件不断增大，会触发自动重写，当然也可以手动重写
> 也就是说 AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。

> AOF 文件重写触发机制：通过 redis.conf 配置文件中的 auto-aof-rewrite-percentage：默认值为100，以及auto-aof-rewrite-min-size：64mb 配置，也就是说默认Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。
>   这里再提一下，我们知道 Redis 是单线程工作，如果 重写 AOF 需要比较长的时间，那么在重写 AOF 期间，Redis将长时间无法处理其他的命令，这显然是不能忍受的。Redis为了克服这个问题，解决办法是将 AOF 重写程序放到子程序中进行，这样有两个好处：
>   ①、子进程进行 AOF 重写期间，服务器进程（父进程）可以继续处理其他命令。
>   ②、子进程带有父进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。
>   使用子进程解决了上面的问题，但是新问题也产生了：因为子进程在进行 AOF 重写期间，服务器进程依然在处理其它命令，这新的命令有可能也对数据库进行了修改操作，使得当前数据库状态和重写后的 AOF 文件状态不一致。
>   为了解决这个数据状态不一致的问题，Redis 服务器设置了一个 AOF 重写缓冲区，这个缓冲区是在创建子进程后开始使用，当Redis服务器执行一个写命令之后，就会将这个写命令也发送到 AOF 重写缓冲区。当子进程完成 AOF 重写之后，就会给父进程发送一个信号，父进程接收此信号后，就会调用函数将 AOF 重写缓冲区的内容都写到新的 AOF 文件中。
>   这样将 AOF 重写对服务器造成的影响降到了最低。

### redis的事务
使用关键字multi开启事务， 使用exec执行事务中的语句，它可以执行多条语句， 所有的命令按照先进先运行的的运行， 不会被其他的命令加塞。

### 并发
redis是单线程的，线程安全，但是有并发问题，redis有事务，但是没有原子性，避免并发冲突可以用
```
watch
get和set改为incr或者incrby
```

### 内存淘汰机制
redis 提供了6种数据淘汰策略：

>volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据进行淘汰
volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据进行淘汰
volatile-random：从已设置过期时间的数据集（server.db[i].expires）中选择任意数据进行淘汰
allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（最常用）
allkeys-random：从数据集（server.db[i].dict）中选择任意数据进行淘汰
no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错

>4.0版本后，又新增加了以下两种：
volatile-lfu：从已设置过期时间的数据集 (server.db[i].expires) 中挑选最不经常使用的数据进行淘汰
allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

### redis集群
#### 哈希槽
[redis cluster集群——高可用 （哈希槽）](https://blog.csdn.net/Rapig1/article/details/102488359)
[吃透了这些Redis知识点，面试官一定觉得你很NB](https://zhuanlan.zhihu.com/p/68694458)

### redis优化思路
1、缓存雪崩
缓存雪崩指的是大批量缓存在同一时间失效或者是缓存层支撑不住宕机，导致流量直接涌入数据库中，会造成数据库压力过大甚至挂掉。

方法：
把每个key的失效时间都加个随机值，保证数据不在同一时间大面积失效。

```EXPIRE key seconds```
2、缓存穿透
[python-布隆过滤器](https://www.cnblogs.com/yscl/p/12003359.html)
缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑，如果从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询， 失去了缓存保护后端存储的意义。

方法一:当DB和redis中都不存在key，在DB返回null时，在redis中插入当key再次请求时,redis直接返回null，而不用再次请求DB。
方法二:使用redis提供的redisbloom，同样是将存在的key放入到过滤器中。当请求进来时，先去过滤器中校验是否存在，如果不存在直接返回null。

3、缓存击穿
缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

方法：
热点数据永不过期
重建热点key时，加互斥锁

4、缓存与数据库双写不一致
解决方案如下:
- 对于并发几率很小的数据(如个人维度的订单数据、用户数据等)，这种几乎不用考虑这个问题，很少会发生缓存不一致，可以给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。
- 就算并发很高，如果业务上能容忍短时间的缓存数据不一致(如商品名称，商品分类菜单等)，缓存加上过期 时间依然可以解决大部分业务对于缓存的要求。
- 如果不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相 当于无锁。
- 也可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加 了系统的复杂度。

### 过期策略
- 定时删除：时间到删除
- 懒惰式删除：每次使用检查是否过期，然后删除
- 定期删除：每隔一段时间检查是否过期

redis采用的策略
懒汉式删除+定期删除

### 修改配置文件
1、修改密码
config set requirepass test123
2、数据库个数
Redis的数据库个数默认是16个（0-15），修改方式是修改redis.conf配置文件databases参数后的数量，重启redis后生效

## 2、mysql
mysql结构：引擎+server层
mysql是由server层和存储引擎
mysql中的数据表类型：INNODB和BDB类 


### 慢查询
[MySQL数据库慢查询问题排查方法](https://zhuanlan.zhihu.com/p/66275448)
慢查询的数量保存在mysql库里面的slow_log表。
```
SELECT * FROM slow_log where start_time > '2019/05/19 00:00:00'; 
```
原因可能有很多
- 大量查询堵塞

慢查询多的时候会有提示吗？似乎没有需要自己统计分析

### 查询优化
[万字总结：学习MySQL优化原理，这一篇就够了！](https://dbaplus.cn/news-155-1531-1.html)
- 加索引
- 尽量不用全表遍历的语句

### 分析查询
可以通过explain查看sql语句的执行计划，通过执行计划来分析索引使用情况

### 日志
[必须了解的mysql三大日志-binlog、redo log和undo log](https://segmentfault.com/a/1190000023827696)
mysql中有事务日志redo和undo日志，二进制日志bilnlog，还有查询日志，慢查询日志，错误日志

- undo日志：保存修改前的值
- redo日志：保存修改后的值
- binlog日志：保存所有修改操作命令

|维度|redo log|binlog|
|:---|:---|:---|
|文件大小|redo log 的大小是固定的。|	binlog 可通过配置参数 max_binlog_size 设置每个 binlog 文件的大小。|
|实现方式|redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。|	binlog 是 Server 层实现的，所有引擎都可以使用 binlog 日志|
|记录方式|redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。	|binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上|
|适用场景|	redo log 适用于崩溃恢复(crash-safe)|	binlog 适用于主从复制和数据恢复|

#### binlog
使用mysqlbinlog 恢复数据
```
# 查看binlog
mysqlbinlog mysql-bin.000006 > 1.sql
# 恢复数据
mysqlbinlog mysql-bin.000006 --start-position=2471 --stop-position=2876 | mysql -uroot -p123
# 跳过/删除部分数据
# 待补充
```
### 引擎
常用的是InnoDB和MyISAM
事务：MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持，提供事务支持已经外部键等高级数据库功能。
性能：MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快。
行数保存：InnoDB 中不保存表的具体行数，也就是说，执行select count() fromtable时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count()语句包含where条件时，两种表的操作是一样的。
索引存储：对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引。MyISAM支持全文索引（FULLTEXT）、压缩索引，InnoDB不支持
锁的支持：MyISAM只支持表锁。InnoDB支持表锁、行锁。行锁大幅度提高了多用户并发操作的性能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。

## 3、mongodb
查询功能比较强大，擅长查询 JSON 数据，能存储海量数据，但是不支持事务。

# 数据库存储与内存，qps与cpu关系

# 数据库数据备份和迁移

# 安全
- 如何避免sql注入？
如果知道目标数据的类型，通过判断整型或者判断是否存在特殊符号，就可以避免，但是假如输入的参数本身就是文本，那就有可能有问题了，但是有个简单的方法，将空格等特殊字符替换为某些特殊字符，或者文本直接以二进制的形式存储，使用的时候再逆处理一遍即可。
- 数据库崩溃怎么办？redis和主数据库连接的时候崩溃怎么办？

## 面试问题
1、数据库的数据是实时更新的吗？每点击一次，数据库数据修改一次？
这个我没有找到答案，我认为是实时更新的，如果数据库没有设置主从结构的话，每点击一次数据也就修改一次。